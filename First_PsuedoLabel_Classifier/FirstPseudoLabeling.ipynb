{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used GPU: GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "####################        Test if an GPU is available     #################################\n",
    "if torch.cuda.is_available():     \n",
    "    print('used GPU: ' + torch.cuda.get_device_name(0))\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    kwar = {'num_workers': 8, 'pin_memory': True}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "    \n",
    "else:\n",
    "    print(\"Warning: CUDA not found, CPU only.\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    kwar = {}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "\n",
    "np.random.seed(551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################        Predefine some Variables        #################################\n",
    "dataDir = '../../resized'                                                      # path to directory of medical MNIST images\n",
    "numEpochs = 10                                                              # number of epochs\n",
    "batchSize = 300                                                             # size of batches\n",
    "t2vRatio = 1.2                                                              # Maximum allowed ratio of validation to training loss\n",
    "t2vEpochs = 3                                                               # Number of consecutive epochs before halting if validation loss exceeds above limit\n",
    "running_loss = 0.0                                                          # running loss\n",
    "lRate = 0.001                                                               # learning rate of classifier\n",
    "momentum = 0.9                                                              # adds a proportion of the previous weight changes to the current weight changes\n",
    "validFrac = 0.1                                                             # fraction of images for validation dataset\n",
    "testFrac = 0.1                                                              # fraction of images for test dataset\n",
    "\n",
    "numConvs1   = 5                                                             # number of channels produced by the convolution\n",
    "convSize1   = 7                                                             # size of the convolving kernel\n",
    "numConvs2   = 10                                                            # number of channels produced by the convolution\n",
    "convSize2   = 7                                                             # size of the convolving kernel\n",
    "\n",
    "fcSize1 = 400                                                               # size of sample\n",
    "fcSize2 = 80                                                                # size of sample\n",
    "\n",
    "validList = []                                                              # list for valid data\n",
    "testList = []                                                               # list for test data\n",
    "trainList = []                                                              # list for train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58954 images in 6 distinct categories\n",
      "Label names: ['HeadCT', 'AbdomenCT', 'BreastMRI', 'Hand', 'ChestCT', 'CXR']\n",
      "Label counts: [10000, 10000, 8954, 10000, 10000, 10000]\n",
      "Image dimensions: 64 x 64\n"
     ]
    }
   ],
   "source": [
    "####################        Read and Prepare Images         #################################\n",
    "classNames = os.listdir(dataDir)                                            # Each type of image can be found in its own subdirectory\n",
    "numClass = len(classNames)                                                  # Number of types = number of subdirectories\n",
    "imageFiles = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
    "            for i in range(numClass)]                                     # nested list of filenames\n",
    "numEach = [len(imageFiles[i]) for i in range(numClass)]                     # count of each type of image\n",
    "imageFilesList = []                                                         # un-nested list of filenames\n",
    "imageClass = []                                                             # The labels -- the type of each individual image in the list\n",
    "for i in range(numClass):\n",
    "    imageFilesList.extend(imageFiles[i])\n",
    "    imageClass.extend([i]*numEach[i])\n",
    "numTotal = len(imageClass)                                                  # Total number of images\n",
    "imageWidth, imageHeight = Image.open(imageFilesList[0]).size                # The dimensions of each image\n",
    "\n",
    "print(\"There are\",numTotal,\"images in\",numClass,\"distinct categories\")\n",
    "print(\"Label names:\",classNames)\n",
    "print(\"Label counts:\",numEach)\n",
    "print(\"Image dimensions:\",imageWidth,\"x\",imageHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################        Define the teacher neural network       #################################\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,xDim,yDim,numC):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,numConvs1,convSize1)                       # first convolutional layer\n",
    "        #self.pool = nn.MaxPool2d(2,2)                                      # max pooling layer\n",
    "        self.conv2 = nn.Conv2d(numConvs1,numConvs2, convSize2)              # second convolutional layer\n",
    "\n",
    "        self.fc1 = nn.Linear(numConvs2*(xDim-(convSize1-1)-(convSize2-1))*(yDim-(convSize1-1)-(convSize2-1)), fcSize1)    # first fully connected layer\n",
    "        self.fc2 = nn.Linear(fcSize1,fcSize2)                               # second fully connected layer\n",
    "        self.fc3 = nn.Linear(fcSize2,numClass)                              # third fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))                              # first conv layer with relu activation function\n",
    "        # x = self.pool(F.relu(self.conv2(x)))                              # second conv layer with relu activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))                                             # first fc layer with relu activation function\n",
    "        x = F.relu(self.fc2(x))                                             # second fc layer with relu activation function\n",
    "        x = self.fc3(x)                                                     # output layer\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):                                         # Count the individual nodes in a layer\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
