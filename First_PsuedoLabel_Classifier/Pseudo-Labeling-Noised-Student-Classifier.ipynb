{
 "cells": [
  {
   "source": [
    "# Pseudo-Labeling-Noised-Student-Classifier"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Script trains a Teacher Net on labeled data. The teacher net is used to pseudo label some unlabeled data. On this expanded dataset the student net is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: CUDA not found, CPU only.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing\n",
    "\n",
    "####################        Test if an GPU is available     #################################\n",
    "if torch.cuda.is_available():     \n",
    "    print('used GPU: ' + torch.cuda.get_device_name(0))\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    kwar = {'num_workers': 8, 'pin_memory': True}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "    \n",
    "else:\n",
    "    print(\"Warning: CUDA not found, CPU only.\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    kwar = {}\n",
    "    cpu = torch.device(\"cpu\")\n",
    "\n",
    "np.random.seed(551)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefine some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################        Predefine some Variables        #################################\n",
    "dataDir = '../../resized'              # path to directory of medical MNIST images\n",
    "\n",
    "validListStud = []                          # list for valid data\n",
    "testListStud = []                           # list for test data\n",
    "trainListStud = []                          # list for train data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#************ Teacher Net ****************************#\n",
    "#**** Net Parameters ****#\n",
    "numConvsTeach1   = 5                        # number of channels produced by the convolution\n",
    "convSizeTeach1   = 7                        # size of the convolving kernel\n",
    "numConvsTeach2   = 10                       # number of channels produced by the convolution\n",
    "convSizeTeach2   = 7                        # size of the convolving kernel\n",
    "\n",
    "fcSizeTeach1 = 400                          # size of sample\n",
    "fcSizeTeach2 = 80                           # size of sample\n",
    "\n",
    "#**** Training Parameters ****#\n",
    "testSizeTeach= 0.8                          # fraction of images for test dataset\n",
    "\n",
    "numEpochsTeach = 10                         # number of epochs\n",
    "batchSizeTeach = 300                        # size of batches\n",
    "lRateTeach = 0.001                          # learning rate of classifier\n",
    "momentumTeach = 0.9                         # adds a proportion of the previous weight changes to the current weight changes\n",
    "\n",
    "t2vRatioTeach = 1.2                         # Maximum allowed ratio of validation to training loss\n",
    "t2vEpochsTeach = 3                          # Number of consecutive epochs before halting if validation loss exceeds above limit\n",
    "\n",
    "#**** DataSet Parameters ****#\n",
    "sameClassOccTeach = True                    # Every Class has same count of images in test and training set\n",
    "\n",
    "#**** Pseudo labeling Parameters ****#\n",
    "SmallerFactor = 0.6                         # Factor for calculating difference between first and second prediction \n",
    "pseudoX_train = []                          # list of train imagesdata\n",
    "pseudoY_train = []                          # list of pseudo labeled train data\n",
    "pseudoX_test = []\n",
    "pseudoY_test = []\n",
    "\n",
    "\n",
    "\n",
    "#************ Student Net ****************************#\n",
    "#**** Net Parameters ****#\n",
    "numConvsStud1   = 5                         # number of channels produced by the convolution\n",
    "convSizeStud1   = 7                         # size of the convolving kernel\n",
    "numConvsStud2   = 10                        # number of channels produced by the convolution\n",
    "convSizeStud2   = 7                         # size of the convolving kernel\n",
    "\n",
    "fcSizeStud1 = 400                           # size of sample\n",
    "fcSizeStud2 = 80                            # size of sample\n",
    "\n",
    "#**** Training Parameters ****#\n",
    "testSizeStud = 0.8                          # fraction of images for test dataset\n",
    "\n",
    "numEpochsStud = 10                          # number of epochs\n",
    "batchSizeStud = 300                         # size of batches\n",
    "lRateStud = 0.001                           # learning rate of classifier\n",
    "momentumStud = 0.9                          # adds a proportion of the previous weight changes to the current weight changes\n",
    "\n",
    "t2vRatioStud = 1.2                          # Maximum allowed ratio of validation to training loss\n",
    "t2vEpochsStud = 3                           # Number of consecutive epochs before halting if validation loss exceeds above limit\n",
    "\n",
    "#**** DataSet Parameters ****#\n",
    "sameClassOccStud = True                     # Every Class has same count of images in test and training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Scale and Prepare Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 53724 images in 6 distinct categories\n",
      "Label names: ['HeadCT', 'AbdomenCT', 'BreastMRI', 'Hand', 'ChestCT', 'CXR']\n",
      "Label counts: [10000, 10000, 8954, 10000, 10000, 10000]\n",
      "Image dimensions: 64 x 64\n",
      "Rescaled min pixel value = -0.774; Max = 0.972; Mean = -2.9e-09\n",
      "tensor(1791)\n",
      "tensor(1790)\n",
      "tensor(1790)\n",
      "tensor(1791)\n",
      "tensor(1791)\n",
      "tensor(1791)\n"
     ]
    }
   ],
   "source": [
    "####################        Read and Prepare Images         #################################\n",
    "classNames = os.listdir(dataDir)                                            # Each type of image can be found in its own subdirectory\n",
    "numClass = len(classNames)                                                  # Number of types = number of subdirectories\n",
    "imageFiles = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
    "            for i in range(numClass)]                                       # nested list of filenames\n",
    "numEach = [len(imageFiles[i]) for i in range(numClass)]                     # count of each type of image\n",
    "imageFilesList = []                                                         # un-nested list of filenames\n",
    "imageClass = []                                                             # The labels -- the type of each individual image in the list\n",
    "if sameClassOccTeach == True:\n",
    "    for i in range(numClass):\n",
    "        imageFilesList.extend(imageFiles[i][:np.min(numEach)])\n",
    "        imageClass.extend([i]*np.min(numEach))\n",
    "else:\n",
    "    for i in range(numClass):\n",
    "        imageFilesList.extend(imageFiles[i])\n",
    "        imageClass.extend([i]*numEach[i])\n",
    "\n",
    "numTotal = len(imageClass)                                                  # Total number of images\n",
    "imageWidth, imageHeight = Image.open(imageFilesList[0]).size                # The dimensions of each image\n",
    "\n",
    "print(\"There are\",numTotal,\"images in\",numClass,\"distinct categories\")\n",
    "print(\"Label names:\",classNames)\n",
    "print(\"Label counts:\",numEach)\n",
    "print(\"Image dimensions:\",imageWidth,\"x\",imageHeight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################        Store and Rescale Images               #################################\n",
    "toTensor = torchvision.transforms.ToTensor()\n",
    "def scaleImage(x):                                                          # Pass a PIL image, return a tensor\n",
    "    y = toTensor(x)\n",
    "    if(y.min() < y.max()):                                                  # Assuming the image isn't empty, rescale so its values run from 0 to 1\n",
    "        y = (y - y.min())/(y.max() - y.min()) \n",
    "    z = y - y.mean()                                                        # Subtract the mean value of the image\n",
    "    return z\n",
    "\n",
    "imageTensor = torch.stack([scaleImage(Image.open(x)) for x in imageFilesList])  # Create image (X) tensor\n",
    "classTensor = torch.tensor(imageClass)                                          # Create label (Y) tensor  \n",
    "print(\"Rescaled min pixel value = {:1.3}; Max = {:1.3}; Mean = {:1.3}\"\n",
    "        .format(imageTensor.min().item(),imageTensor.max().item(),imageTensor.mean().item()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################        Seperate DataSet to Train/Test          #################################\n",
    "x_train, x_test, y_train, y_test = train_test_split(imageTensor, classTensor, test_size=testSizeTeach, random_state=4, shuffle=True, stratify=classTensor)\n",
    "\n",
    "for i in range(numClass):\n",
    "    print(sum(y_train==i))                                                # check the count of images in every class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################        Define the teacher neural network       #################################\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self,xDim,yDim,numC):\n",
    "        super(TeacherNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,numConvsTeach1,convSizeTeach1)                       # first convolutional layer\n",
    "        #self.pool = nn.MaxPool2d(2,2)                                      # max pooling layer\n",
    "        self.conv2 = nn.Conv2d(numConvsTeach1,numConvsTeach2, convSizeTeach2)              # second convolutional layer\n",
    "\n",
    "        self.fc1 = nn.Linear(numConvsTeach2*(xDim-(convSizeTeach1-1)-(convSizeTeach2-1))*\n",
    "                             (yDim-(convSizeTeach1-1)-(convSizeTeach2-1)), fcSizeTeach1)    # first fully connected layer\n",
    "        self.fc2 = nn.Linear(fcSizeTeach1,fcSizeTeach2)                               # second fully connected layer\n",
    "        self.fc3 = nn.Linear(fcSizeTeach2,numClass)                              # third fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))                              # first conv layer with relu activation function\n",
    "        # x = self.pool(F.relu(self.conv2(x)))                              # second conv layer with relu activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))                                             # first fc layer with relu activation function\n",
    "        x = F.relu(self.fc2(x))                                             # second fc layer with relu activation function\n",
    "        x = self.fc3(x)                                                     # output layer\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):                                         # Count the individual nodes in a layer\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################        Define the student neural network       #################################\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self,xDim,yDim,numC):\n",
    "        super(StudentNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,numConvsStud1,convSizeStud1)               # first convolutional layer\n",
    "        #self.pool = nn.MaxPool2d(2,2)                                      # max pooling layer\n",
    "        self.conv2 = nn.Conv2d(numConvsStud1,numConvsStud2, convSizeStud2)  # second convolutional layer\n",
    "\n",
    "        self.fc1 = nn.Linear(numConvsStud2*(xDim-(convSizeStud1-1)-(convSizeStud2-1))*(yDim-(convSizeStud1-1)-(convSizeStud2-1)), fcSizeStud1)    # first fully connected layer\n",
    "        self.fc2 = nn.Linear(fcSizeStud1,fcSizeStud2)                       # second fully connected layer\n",
    "        self.fc3 = nn.Linear(fcSizeStud2,numClass)                          # third fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))                              # first conv layer with relu activation function\n",
    "        # x = self.pool(F.relu(self.conv2(x)))                              # second conv layer with relu activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))                                             # first fc layer with relu activation function\n",
    "        x = F.relu(self.fc2(x))                                             # second fc layer with relu activation function\n",
    "        x = self.fc3(x)                                                     # output layer\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):                                         # Count the individual nodes in a layer\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the teacher model and pseudolabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =   0; Training loss = 64.4446\n",
      "Epoch =   1; Training loss = 64.1013\n",
      "Epoch =   2; Training loss = 63.0299\n",
      "Epoch =   3; Training loss = 55.7356\n",
      "Epoch =   4; Training loss = 27.8125\n",
      "Epoch =   5; Training loss = 13.6037\n",
      "Epoch =   6; Training loss = 9.5318\n",
      "Epoch =   7; Training loss = 7.9737\n",
      "Epoch =   8; Training loss = 7.0403\n",
      "Epoch =   9; Training loss = 6.3113\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "####################        Training the teacher neural network       #################################\n",
    "teachernet = TeacherNet(imageWidth,imageHeight,numClass).cuda()                    # create neural network\n",
    "criterion = nn.CrossEntropyLoss()                                           # set criterion\n",
    "optimizer = optim.SGD(teachernet.parameters(), lr=lRateTeach, momentum=momentumTeach) # set optimizer to squared gradient decent\n",
    "\n",
    "trainBats = x_train.size()[0] // batchSizeTeach                             # Number of training batches per epoch. Round down to simplify last batch\n",
    "testBats = -(-x_test.size()[0] // batchSizeTeach)                           # Testing batches. Round up to include all\n",
    "\n",
    "for epoch in range(numEpochsTeach):\n",
    "    epochLoss = 0\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(x_train.size()[0])\n",
    "\n",
    "    for i in range(0,x_train.size()[0], batchSizeTeach):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batchSizeTeach]\n",
    "        batch_x, batch_y = x_train[indices], y_train[indices]\n",
    "\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = teachernet.forward(batch_x.to(dev))\n",
    "        loss = F.cross_entropy(outputs,batch_y.to(dev))\n",
    "        epochLoss += loss.item()                                            # Add loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch = {:-3}; Training loss = {:.4f}\".format(epoch,epochLoss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:  40905 of 42980 ( 95.1721731037692 %)\n",
      "[[6642  108    1   33  379    0]\n",
      " [ 107 6607   86    0  364    0]\n",
      " [   0   22 7106    0   36    0]\n",
      " [ 161   18   11 6927   28   18]\n",
      " [  14  373   87   26 6663    0]\n",
      " [  14   16    9  124   40 6960]]\n"
     ]
    }
   ],
   "source": [
    "####################        Evaluate the teacher Net and Pseudo Label Data        #################################\n",
    "confuseMtx = np.zeros((numClass,numClass),dtype=int)\n",
    "evalMat = []\n",
    "\n",
    "counter = 0\n",
    "for j in range(len(x_test)):\n",
    "    pred = teachernet(x_test[j].reshape(1,1,imageWidth,imageHeight).to(dev))\n",
    "    \n",
    "    # Is-Class - Predicted-CLass - Prediction-Value\n",
    "    evalMat.append([int(y_test[j].cpu().numpy()), pred.max(1)[1].cpu().numpy()[0], pred.max(1)[0].cpu().detach().numpy()[0]])\n",
    "    confuseMtx[int(y_test[j].cpu().numpy()),pred.max(1)[1].cpu().numpy()[0]] += 1\n",
    "    secElemSmallEnough = np.sort(pred.cpu().detach().numpy())[0][-2]< np.sort(pred.cpu().detach().numpy())[0][-1]*SmallerFactor\n",
    "    \n",
    "    \n",
    "    if (pred.max(1)[0].cpu().detach().numpy()[0] >= 10.0) and secElemSmallEnough:\n",
    "        #print(str(counter) + \": \"+ str(pred.max(1)[0].cpu().detach().numpy()[0]))\n",
    "        pseudoX_train.append(x_test[j].numpy())\n",
    "        pseudoY_train.append(pred.max(1)[1].cpu().numpy()[0])\n",
    "        counter += 1\n",
    "\n",
    "    else:\n",
    "        pseudoX_test.append(x_test[j].numpy())\n",
    "        pseudoY_test.append(y_test[j])\n",
    "\n",
    "correct = sum([confuseMtx[i,i] for i in range(numClass)])   # Sum over diagonal elements to count correct predictions\n",
    "percentage = correct/len(x_test)*100\n",
    "print(\"Correct predictions: \",correct,\"of\",len(x_test),\"(\",percentage,\"%)\")\n",
    "print(confuseMtx)    \n",
    "#print(evalMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test and training dataset for student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudoX_test: torch.Size([42980, 1, 64, 64]) Type: torch.FloatTensor\n",
      "x_test: torch.Size([42980, 1, 64, 64]) Type: torch.FloatTensor\n",
      "pseudoY_test: torch.Size([26078]) Type: torch.LongTensor\n",
      "y_test: torch.Size([42980]) Type: torch.LongTensor\n",
      "pseudoX_train: torch.Size([10744, 1, 64, 64]) Type: torch.FloatTensor\n",
      "x_train: torch.Size([10744, 1, 64, 64]) Type: torch.FloatTensor\n",
      "pseudoY_train: torch.Size([27646]) Type: torch.LongTensor\n",
      "y_train: torch.Size([10744]) Type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "####################        Noise the pseudo labeled data        #################################\n",
    "pseudoX_test = torch.tensor(pseudoX_test)\n",
    "pseudoY_test = torch.LongTensor(pseudoY_test)\n",
    "pseudoX_train = torch.cat((x_train, torch.Tensor(pseudoX_train)), 0)\n",
    "pseudoY_train = torch.cat((y_train, torch.LongTensor(pseudoY_train)), 0)\n",
    "\n",
    "colorjitter = torchvision.transforms.ColorJitter(hue=.05, saturation=.05)\n",
    "horizontalFlip = torchvision.transforms.RandomHorizontalFlip()\n",
    "randomRotation = torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "for img in range(len(pseudoX_train)):\n",
    "    random = np.random.rand(1)\n",
    "    if random <= 0.25:\n",
    "        pass\n",
    "        #pseudoX_train[img] = colorjitter(pseudoX_train[img])\n",
    "    elif random <= 0.5 and random > 0.25:\n",
    "        pseudoX_train[img] = horizontalFlip(pseudoX_train[img])\n",
    "    elif random <= 0.75 and random >0.5:\n",
    "        pseudoX_train[img] = randomRotation(pseudoX_train[img])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"pseudoX_test: \" + str(x_test.size()) + \" Type: \" + str(pseudoX_test.type()))\n",
    "print(\"x_test: \" + str(x_test.size()) + \" Type: \" + str(x_test.type()))\n",
    "print(\"pseudoY_test: \" + str(pseudoY_test.size()) + \" Type: \" + str(pseudoY_test.type()))\n",
    "print(\"y_test: \" + str(y_test.size()) + \" Type: \" + str(y_test.type()))\n",
    "\n",
    "print(\"pseudoX_train: \" + str(x_train.size()) + \" Type: \" + str(pseudoX_train.type()))\n",
    "print(\"x_train: \" + str(x_train.size()) + \" Type: \" + str(x_train.type()))\n",
    "print(\"pseudoY_train: \" + str(pseudoY_train.size()) + \" Type: \" + str(pseudoY_train.type()))\n",
    "print(\"y_train: \" + str(y_train.size()) + \" Type: \" + str(y_train.type()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Train the Student Network with Pseudo-Label DataSet\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =   0; Training loss = 131.6592\n",
      "Epoch =   1; Training loss = 23.5390\n",
      "Epoch =   2; Training loss = 12.4433\n",
      "Epoch =   3; Training loss = 9.6472\n",
      "Epoch =   4; Training loss = 8.2877\n",
      "Epoch =   5; Training loss = 7.3583\n",
      "Epoch =   6; Training loss = 6.7528\n",
      "Epoch =   7; Training loss = 6.1330\n",
      "Epoch =   8; Training loss = 5.6397\n",
      "Epoch =   9; Training loss = 5.2098\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "####################        Training the student neural network       #################################\n",
    "studentnet = StudentNet(imageWidth,imageHeight,numClass).cuda()                           # create neural network\n",
    "criterionStud = nn.CrossEntropyLoss()                                           # set criterion\n",
    "optimizerStud = optim.SGD(studentnet.parameters(), lr=lRateStud, momentum=momentumStud)        # set optimizer to squared gradient decent\n",
    "\n",
    "trainBats = pseudoX_train.size()[0] // batchSizeStud                                             # Number of training batches per epoch. Round down to simplify last batch\n",
    "testBats = -(-pseudoX_test.size()[0] // batchSizeStud)                                           # Testing batches. Round up to include all\n",
    "\n",
    "for epoch in range(numEpochsStud):\n",
    "    epochLoss = 0\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(pseudoX_train.size()[0])\n",
    "\n",
    "    for i in range(0,pseudoX_train.size()[0], batchSizeStud):\n",
    "        optimizerStud.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batchSizeStud]\n",
    "        batch_x_stud, batch_y_stud = pseudoX_train[indices], pseudoY_train[indices]\n",
    "        \n",
    "        # in case you wanted a semi-full example\n",
    "        outputsStud = studentnet.forward(batch_x_stud.to(dev))\n",
    "        loss = F.cross_entropy(outputsStud,batch_y_stud.to(dev))\n",
    "        epochLoss += loss.item()                                            # Add loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerStud.step()\n",
    "\n",
    "\n",
    "    print(\"Epoch = {:-3}; Training loss = {:.4f}\".format(epoch,epochLoss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:  24455 of 26078 ( 93.7763632180382 %)\n",
      "[[4323   96    0   67  364    8]\n",
      " [  10 6784   64    5  117    0]\n",
      " [   0   14 2564    0   21    8]\n",
      " [  65   44   12 1869   25   20]\n",
      " [   0  450  105   24 6584    0]\n",
      " [   4   17    7   50   26 2331]]\n"
     ]
    }
   ],
   "source": [
    "####################        Evaluate the student network on bad predicted test set       #################################\n",
    "confuseMtx = np.zeros((numClass,numClass),dtype=int)\n",
    "evalMat = []\n",
    "for j in range(len(pseudoX_test)):\n",
    "    #np.shape(x_test[j].reshape(1,1,64,64))\n",
    "    #plt.figure()\n",
    "    #plt.imshow((x_test[j]).reshape(64,64))\n",
    "    #print(str(y_test[j]) + \": \" + str(classNames[y_test[j]]))\n",
    "    pred = studentnet(pseudoX_test[j].reshape(1,1,imageWidth,imageHeight).to(dev))\n",
    "    #print(pred.max(1,keepdim=True))\n",
    "    \n",
    "    # Is-Class - Predicted-CLass - Prediction-Value\n",
    "    evalMat.append([int(pseudoY_test[j].cpu().numpy()), pred.max(1)[1].cpu().numpy()[0], pred.max(1)[0].cpu().detach().numpy()[0]])\n",
    "    confuseMtx[int(pseudoY_test[j].cpu().numpy()),pred.max(1)[1].cpu().numpy()[0]] += 1\n",
    "correct = sum([confuseMtx[i,i] for i in range(numClass)])   # Sum over diagonal elements to count correct predictions\n",
    "percentage = correct/len(pseudoX_test)*100\n",
    "print(\"Correct predictions: \",correct,\"of\",len(pseudoX_test),\"(\",percentage,\"%)\")\n",
    "print(confuseMtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:  41342 of 42980 ( 96.18892508143323 %)\n",
      "[[6623  101    0   67  364    8]\n",
      " [  10 6968   64    5  117    0]\n",
      " [   0   14 7121    0   21    8]\n",
      " [  66   46   15 6991   25   20]\n",
      " [   0  450  105   24 6584    0]\n",
      " [   4   21    7   50   26 7055]]\n"
     ]
    }
   ],
   "source": [
    "####################        Evaluate the student net on whole test dataset       #################################\n",
    "confuseMtx = np.zeros((numClass,numClass),dtype=int)\n",
    "evalMat = []\n",
    "for j in range(len(x_test)):\n",
    "\n",
    "    pred = studentnet(x_test[j].reshape(1,1,imageWidth,imageHeight).to(dev))\n",
    "    #print(pred.max(1,keepdim=True))\n",
    "    \n",
    "    # Is-Class - Predicted-CLass - Prediction-Value\n",
    "    evalMat.append([int(y_test[j].cpu().numpy()), pred.max(1)[1].cpu().numpy()[0], pred.max(1)[0].cpu().detach().numpy()[0]])\n",
    "    confuseMtx[int(y_test[j].cpu().numpy()),pred.max(1)[1].cpu().numpy()[0]] += 1\n",
    "correct = sum([confuseMtx[i,i] for i in range(numClass)])   # Sum over diagonal elements to count correct predictions\n",
    "percentage = correct/len(x_test)*100\n",
    "print(\"Correct predictions: \",correct,\"of\",len(x_test),\"(\",percentage,\"%)\")\n",
    "print(confuseMtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teachernet, 'MedNIST_PseudoLabel_Teachernet')\n",
    "torch.save(studentnet, 'MedNIST_PseudoLabel_Studentnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}