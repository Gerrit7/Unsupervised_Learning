{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_name DATA_NAME]\n",
      "                             [--input_root INPUT_ROOT]\n",
      "                             [--output_root OUTPUT_ROOT]\n",
      "                             [--num_epoch NUM_EPOCH] [--download DOWNLOAD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/gerrit/.local/share/jupyter/runtime/kernel-2f8aaee1-8f9d-4513-8bdd-9243ce3dc87d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from medmnist.models import ResNet18, ResNet50\n",
    "from medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, \\\n",
    "    BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal\n",
    "from medmnist.evaluator import getAUC, getACC, save_results\n",
    "from medmnist.info import INFO\n",
    "\n",
    "\n",
    "def main(flag, input_root, output_root, end_epoch, download):\n",
    "    ''' main function\n",
    "    :param flag: name of subset\n",
    "\n",
    "    '''\n",
    "\n",
    "    flag_to_class = {\n",
    "        \"pathmnist\": PathMNIST,\n",
    "        \"chestmnist\": ChestMNIST,\n",
    "        \"dermamnist\": DermaMNIST,\n",
    "        \"octmnist\": OCTMNIST,\n",
    "        \"pneumoniamnist\": PneumoniaMNIST,\n",
    "        \"retinamnist\": RetinaMNIST,\n",
    "        \"breastmnist\": BreastMNIST,\n",
    "        \"organmnist_axial\": OrganMNISTAxial,\n",
    "        \"organmnist_coronal\": OrganMNISTCoronal,\n",
    "        \"organmnist_sagittal\": OrganMNISTSagittal,\n",
    "    }\n",
    "    DataClass = flag_to_class[flag]\n",
    "\n",
    "    info = INFO[flag]\n",
    "    task = info['task']\n",
    "    n_channels = info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    start_epoch = 0\n",
    "    lr = 0.001\n",
    "    batch_size = 128\n",
    "    val_auc_list = []\n",
    "    dir_path = os.path.join(output_root, '%s_checkpoints' % (flag))\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    print('==> Preparing data...')\n",
    "    train_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[.5], std=[.5])])\n",
    "\n",
    "    val_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[.5], std=[.5])])\n",
    "\n",
    "    test_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[.5], std=[.5])])\n",
    "\n",
    "    train_dataset = DataClass(root=input_root,\n",
    "                                    split='train',\n",
    "                                    transform=train_transform,\n",
    "                                    download=download)\n",
    "    \n",
    "    train_loader = data.DataLoader(dataset=train_dataset_scaled,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)\n",
    "    val_dataset = DataClass(root=input_root,\n",
    "                                  split='val',\n",
    "                                  transform=val_transform,\n",
    "                                  download=download)\n",
    "    val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True)\n",
    "    test_dataset = DataClass(root=input_root,\n",
    "                                   split='test',\n",
    "                                   transform=test_transform,\n",
    "                                   download=download)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True)\n",
    "    \n",
    "    print('==> Building and training model...')\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResNet18(in_channels=n_channels, num_classes=n_classes).to(device)\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    for epoch in trange(start_epoch, end_epoch):\n",
    "        train(model, optimizer, criterion, train_loader, device, task)\n",
    "        val(model, val_loader, device, val_auc_list, task, dir_path, epoch)\n",
    "\n",
    "    auc_list = np.array(val_auc_list)\n",
    "    index = auc_list.argmax()\n",
    "    print('epoch %s is the best model' % (index))\n",
    "\n",
    "    print('==> Testing model...')\n",
    "    restore_model_path = os.path.join(\n",
    "        dir_path, 'ckpt_%d_auc_%.5f.pth' % (index, auc_list[index]))\n",
    "    model.load_state_dict(torch.load(restore_model_path)['net'])\n",
    "    test(model,\n",
    "         'train',\n",
    "         train_loader,\n",
    "         device,\n",
    "         flag,\n",
    "         task,\n",
    "         output_root=output_root)\n",
    "    test(model, 'val', val_loader, device, flag, task, output_root=output_root)\n",
    "    test(model,\n",
    "         'test',\n",
    "         test_loader,\n",
    "         device,\n",
    "         flag,\n",
    "         task,\n",
    "         output_root=output_root)\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, device, task):\n",
    "    ''' training function\n",
    "    :param model: the model to train\n",
    "    :param optimizer: optimizer used in training\n",
    "    :param criterion: loss function\n",
    "    :param train_loader: DataLoader of training set\n",
    "    :param device: cpu or cuda\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def val(model, val_loader, device, val_auc_list, task, dir_path, epoch):\n",
    "    ''' validation function\n",
    "    :param model: the model to validate\n",
    "    :param val_loader: DataLoader of validation set\n",
    "    :param device: cpu or cuda\n",
    "    :param val_auc_list: the list to save AUC score of each epoch\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "    :param dir_path: where to save model\n",
    "    :param epoch: current epoch\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            outputs = model(inputs.to(device))\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).to(device)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs = m(outputs).to(device)\n",
    "            else:\n",
    "                targets = targets.squeeze().long().to(device)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(outputs).to(device)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc = getAUC(y_true, y_score, task)\n",
    "        val_auc_list.append(auc)\n",
    "\n",
    "    state = {\n",
    "        'net': model.state_dict(),\n",
    "        'auc': auc,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "\n",
    "    path = os.path.join(dir_path, 'ckpt_%d_auc_%.5f.pth' % (epoch, auc))\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def test(model, split, data_loader, device, flag, task, output_root=None):\n",
    "    ''' testing function\n",
    "    :param model: the model to test\n",
    "    :param split: the data to test, 'train/val/test'\n",
    "    :param data_loader: DataLoader of data\n",
    "    :param device: cpu or cuda\n",
    "    :param flag: subset name\n",
    "    :param task: task of current dataset, binary-class/multi-class/multi-label, binary-class\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            outputs = model(inputs.to(device))\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).to(device)\n",
    "                m = nn.Sigmoid()\n",
    "                outputs = m(outputs).to(device)\n",
    "            else:\n",
    "                targets = targets.squeeze().long().to(device)\n",
    "                m = nn.Softmax(dim=1)\n",
    "                outputs = m(outputs).to(device)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc = getAUC(y_true, y_score, task)\n",
    "        acc = getACC(y_true, y_score, task)\n",
    "        print('%s AUC: %.5f ACC: %.5f' % (split, auc, acc))\n",
    "\n",
    "        if output_root is not None:\n",
    "            output_dir = os.path.join(output_root, flag)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.mkdir(output_dir)\n",
    "            output_path = os.path.join(output_dir, '%s.csv' % (split))\n",
    "            save_results(y_true, y_score, output_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='RUN Baseline model of MedMNIST')\n",
    "    parser.add_argument('--data_name',\n",
    "                        default='pathmnist',\n",
    "                        help='subset of MedMNIST',\n",
    "                        type=str)\n",
    "    parser.add_argument('--input_root',\n",
    "                        default='./input',\n",
    "                        help='input root, the source of dataset files',\n",
    "                        type=str)\n",
    "    parser.add_argument('--output_root',\n",
    "                        default='./output',\n",
    "                        help='output root, where to save models and results',\n",
    "                        type=str)\n",
    "    parser.add_argument('--num_epoch',\n",
    "                        default=100,\n",
    "                        help='num of epochs of training',\n",
    "                        type=int)\n",
    "    parser.add_argument('--download',\n",
    "                        default=True,\n",
    "                        help='whether download the dataset or not',\n",
    "                        type=bool)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_name = args.data_name.lower()\n",
    "    input_root = args.input_root\n",
    "    output_root = args.output_root\n",
    "    end_epoch = args.num_epoch\n",
    "    download = args.download\n",
    "    main(data_name,\n",
    "         input_root,\n",
    "         output_root,\n",
    "         end_epoch=end_epoch,\n",
    "         download=download)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data...\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_loader = main(\"retinamnist\", \"../../DataSets/medmnist-20201211T084149Z-001/medmnist\", \"../../TrainedNets/Training_Resnet18_self\", 100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([322, 273, 226,  79, 367, 107, 189,  42, 121, 184, 358, 178, 404, 488,\n",
      "        401, 305, 339, 173,  65, 191,  21, 381, 440, 495, 496, 424, 350, 356,\n",
      "        333, 129, 392, 296, 180, 443, 137, 243, 170, 158, 399, 262, 119, 369,\n",
      "         89, 247, 101, 377, 136, 188, 323, 452])\n",
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(len(train_dataset))[:round(len(train_dataset)*0.1)]\n",
    "print(indices)\n",
    "train_dataset_scaled = []\n",
    "for idx in indices:\n",
    "    train_dataset_scaled.append(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f09977a4ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
